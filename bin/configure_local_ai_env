#!/usr/bin/env bash

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
ENV_FILE="${1:-$ROOT_DIR/.env}"
EXAMPLE_FILE="$ROOT_DIR/config/local_ai.env.example"

VISION_MODEL="${OLLAMA_VISION_MODEL:-llama3.2-vision:11b}"
PRIMARY_MODEL="${OLLAMA_FAST_MODEL:-${OLLAMA_COMMENT_MODEL:-$VISION_MODEL}}"
QUALITY_MODEL="${OLLAMA_QUALITY_MODEL:-$PRIMARY_MODEL}"
BASE_MODEL="${OLLAMA_MODEL:-$VISION_MODEL}"
NUM_CTX="${OLLAMA_NUM_CTX:-3072}"

upsert_kv() {
  local key="$1"
  local value="$2"

  if grep -Eq "^${key}=" "$ENV_FILE"; then
    sed -i "s#^${key}=.*#${key}=${value}#g" "$ENV_FILE"
  else
    printf "%s=%s\n" "$key" "$value" >> "$ENV_FILE"
  fi
}

if [[ ! -f "$ENV_FILE" ]]; then
  if [[ -f "$EXAMPLE_FILE" ]]; then
    cp "$EXAMPLE_FILE" "$ENV_FILE"
    echo "Created $ENV_FILE from config/local_ai.env.example"
  else
    touch "$ENV_FILE"
    echo "Created empty $ENV_FILE"
  fi
fi

upsert_kv "OLLAMA_URL" "${OLLAMA_URL:-http://localhost:11434}"
upsert_kv "USE_LOCAL_AI_MICROSERVICE" "${USE_LOCAL_AI_MICROSERVICE:-true}"
upsert_kv "LOCAL_AI_MICROSERVICE_REQUIRED" "${LOCAL_AI_MICROSERVICE_REQUIRED:-false}"
upsert_kv "LOCAL_AI_ENABLE_VISION" "${LOCAL_AI_ENABLE_VISION:-true}"
upsert_kv "LOCAL_AI_ENABLE_VIDEO" "${LOCAL_AI_ENABLE_VIDEO:-true}"
upsert_kv "LOCAL_AI_ENABLE_FACE" "${LOCAL_AI_ENABLE_FACE:-true}"
upsert_kv "LOCAL_AI_ENABLE_OCR" "${LOCAL_AI_ENABLE_OCR:-true}"
upsert_kv "LOCAL_AI_ENABLE_WHISPER" "${LOCAL_AI_ENABLE_WHISPER:-true}"
upsert_kv "MICROSERVICE_SAFE_MODE_FALLBACK" "${MICROSERVICE_SAFE_MODE_FALLBACK:-true}"
upsert_kv "MICROSERVICE_FORCE_SAFE_MODE" "${MICROSERVICE_FORCE_SAFE_MODE:-false}"
upsert_kv "OLLAMA_MODEL" "$BASE_MODEL"
upsert_kv "OLLAMA_FAST_MODEL" "$PRIMARY_MODEL"
upsert_kv "OLLAMA_QUALITY_MODEL" "$QUALITY_MODEL"
upsert_kv "OLLAMA_VISION_MODEL" "$VISION_MODEL"
upsert_kv "OLLAMA_COMMENT_MODEL" "$PRIMARY_MODEL"
upsert_kv "OLLAMA_VISION_UNDERSTANDING_ENABLED" "${OLLAMA_VISION_UNDERSTANDING_ENABLED:-true}"
upsert_kv "OLLAMA_NUM_CTX" "$NUM_CTX"

upsert_kv "LLM_COMMENT_ENABLE_MODEL_ESCALATION" "${LLM_COMMENT_ENABLE_MODEL_ESCALATION:-true}"
upsert_kv "LLM_COMMENT_ESCALATION_MIN_ACCEPTED" "${LLM_COMMENT_ESCALATION_MIN_ACCEPTED:-5}"
upsert_kv "LLM_COMMENT_ESCALATION_MAX_REJECT_RATIO" "${LLM_COMMENT_ESCALATION_MAX_REJECT_RATIO:-0.45}"
upsert_kv "LLM_COMMENT_ESCALATION_MIN_GROUNDED_RATIO" "${LLM_COMMENT_ESCALATION_MIN_GROUNDED_RATIO:-0.55}"
upsert_kv "LLM_COMMENT_MAX_CONTEXT_JSON_CHARS" "${LLM_COMMENT_MAX_CONTEXT_JSON_CHARS:-3200}"
upsert_kv "LLM_COMMENT_TARGET_CONTEXT_JSON_CHARS" "${LLM_COMMENT_TARGET_CONTEXT_JSON_CHARS:-2600}"
upsert_kv "LLM_COMMENT_PRIMARY_MAX_TOKENS" "${LLM_COMMENT_PRIMARY_MAX_TOKENS:-180}"
upsert_kv "LLM_COMMENT_PRIMARY_RETRY_MAX_TOKENS" "${LLM_COMMENT_PRIMARY_RETRY_MAX_TOKENS:-130}"
upsert_kv "LLM_COMMENT_QUALITY_MAX_TOKENS" "${LLM_COMMENT_QUALITY_MAX_TOKENS:-240}"
upsert_kv "LLM_COMMENT_QUALITY_RETRY_MAX_TOKENS" "${LLM_COMMENT_QUALITY_RETRY_MAX_TOKENS:-170}"

echo "Configured local AI env values in $ENV_FILE"
echo "  OLLAMA_VISION_MODEL=$VISION_MODEL"
echo "  OLLAMA_FAST_MODEL=$PRIMARY_MODEL"
echo "  OLLAMA_QUALITY_MODEL=$QUALITY_MODEL"
echo "  OLLAMA_NUM_CTX=$NUM_CTX"
