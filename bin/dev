#!/usr/bin/env ruby

require "bundler/setup"

# --- Service Refresh Logic ---
def kill_process_on_port(port)
  pid = `lsof -ti tcp:#{port}`.strip
  unless pid.empty?
    puts "ğŸ›‘ Killing process on port #{port} (PID: #{pid})..."
    begin
      Process.kill("TERM", pid.to_i)
      sleep 2
      Process.kill("KILL", pid.to_i) rescue nil
    rescue => e
      puts "âš ï¸  Could not kill process #{pid}: #{e.message}"
    end
  end
end

# Kill Rails (port 3000), AI Microservice (8000), Ollama (11434)
kill_process_on_port(3000)
kill_process_on_port(8000)
kill_process_on_port(11434)

# Kill asset builders (yarn watch, yarn watch:css) and jobs by name
%w[yarn jobs].each do |proc|
  pids = `pgrep -f "#{proc}"`.split
  pids.each do |pid|
    puts "ğŸ›‘ Killing #{proc} process (PID: #{pid})..."
    begin
      Process.kill("TERM", pid.to_i)
      sleep 1
      Process.kill("KILL", pid.to_i) rescue nil
    rescue => e
      puts "âš ï¸  Could not kill #{proc} process #{pid}: #{e.message}"
    end
  end
end

# Remove AI microservice PID file if exists
if File.exist?("tmp/ai_microservice.pid")
  File.delete("tmp/ai_microservice.pid") rescue nil
end

env = ENV.to_h
env["REDIS_URL"] ||= "redis://127.0.0.1:6379/0"

web = ["./bin/rails", "server", *ARGV]
jobs = ["./bin/jobs"]
css = ["yarn", "watch:css"]
js = ["yarn", "watch"]

# Check if local AI services should be started
start_ai_services = ENV.fetch("START_LOCAL_AI", "true") == "true"
ai_services_pids = []

if start_ai_services
  puts "ğŸ¤– Starting Local AI Services..."
  
  # Start Ollama if not running
  ollama_running = system("curl -s http://localhost:11434/api/tags > /dev/null 2>&1")
  unless ollama_running
    puts "ğŸ”¥ Starting Ollama..."
    # Check if Ollama service exists and start it
    if system("systemctl list-unit-files | grep -q ollama.service")
      puts "ğŸ“‹ Starting Ollama systemd service..."
      system("systemctl start ollama")
      sleep 5
    else
      # Start Ollama directly in background
      puts "ğŸ”§ Starting Ollama directly..."
      ai_services_pids << Process.spawn("ollama serve > /dev/null 2>&1")
      sleep 8  # Give more time for Ollama to fully start
    end
  end
  
  # Start AI Microservice if not running
  microservice_running = system("curl -s http://localhost:8000/health > /dev/null 2>&1")
  unless microservice_running
    puts "ğŸ§  Starting AI Microservice..."
    microservice_log = File.expand_path("log/ai_microservice.log", Dir.pwd)
    microservice_env = {
      "PYTHONPATH" => ".",
      "PYTHONUNBUFFERED" => "1",
      "LOCAL_AI_RELOAD" => ENV.fetch("LOCAL_AI_RELOAD", "false"),
      "LOCAL_AI_LOG_LEVEL" => ENV.fetch("LOCAL_AI_LOG_LEVEL", "info")
    }
    
    # Setup microservice if needed
    unless Dir.exist?("ai_microservice/ai_microservice_env")
      puts "ğŸ“¦ Setting up AI Microservice environment..."
      system("cd ai_microservice && ./setup.sh > /dev/null 2>&1")
    end
    
    # Ensure directories exist
    system("mkdir -p tmp log")
    
    # Test basic setup first
    puts "ğŸ§ª Testing microservice setup..."
    test_result = system("cd ai_microservice && ai_microservice_env/bin/python test_setup.py > /dev/null 2>&1")
    
    if test_result
      puts "âœ… Microservice setup looks good"
      # Try full version first
      ai_services_pids << Process.spawn(
        microservice_env,
        "ai_microservice_env/bin/python",
        "main.py",
        chdir: "ai_microservice",
        out: microservice_log,
        err: microservice_log
      )
    else
      puts "âš ï¸  Using simplified microservice (some features may be limited)"
      # Use simplified version
      ai_services_pids << Process.spawn(
        microservice_env,
        "ai_microservice_env/bin/python",
        "main_simple.py",
        chdir: "ai_microservice",
        out: microservice_log,
        err: microservice_log
      )
    end
    
    # Store PID for management
    File.write("tmp/ai_microservice.pid", ai_services_pids.last.to_s)
    sleep 5
  end
  
  # Verify services are running
  ollama_ok = system("curl -s http://localhost:11434/api/tags > /dev/null 2>&1")
  microservice_ok = system("curl -s http://localhost:8000/health > /dev/null 2>&1")
  
  if ollama_ok && microservice_ok
    puts "âœ… Local AI Services started successfully!"
  else
    puts "âš ï¸  Some AI services may not be running. Run './bin/local_ai_services status' to check."
  end
end

pids = []

begin
  puts "ğŸš€ Starting Rails server, background jobs, and asset builders..."
  puts "ğŸ¨ Building assets..."
  
  # Build assets first
  system("yarn build") || puts("âš ï¸  JavaScript build failed")
  system("yarn build:css") || puts("âš ï¸  CSS build failed")
  
  pids << Process.spawn(env, *web)
  pids << Process.spawn(env, *jobs)
  pids << Process.spawn(env, *css)
  pids << Process.spawn(env, *js)
  pids.concat(ai_services_pids)

  # Set up signal handlers for graceful shutdown
  shutdown_services = lambda do |signal_name|
    puts "\nğŸ›‘ Shutting down services (#{signal_name})..."
    
    # Stop Rails and jobs first
    pids[0..3].each { |pid| Process.kill("TERM", pid) rescue nil }
    
    # Give Rails time to shutdown gracefully
    sleep 3
    
    # Stop AI services
    if start_ai_services
      puts "ğŸ¤– Stopping Local AI Services..."
      
      # Stop microservice
      if File.exist?("tmp/ai_microservice.pid")
        microservice_pid = File.read("tmp/ai_microservice.pid").to_i
        Process.kill("TERM", microservice_pid) rescue nil
        sleep 2
        Process.kill("KILL", microservice_pid) rescue nil
        File.delete("tmp/ai_microservice.pid") rescue nil
      end
      
      # Stop Ollama (if we started it)
      ai_services_pids.each { |pid| Process.kill("TERM", pid) rescue nil }
    end
    
    # Wait for all processes to exit
    pids.each { |pid| Process.wait(pid) rescue nil }
    
    puts "ğŸ‘‹ All services stopped. Goodbye!"
    exit(0)
  end

  Signal.trap("INT") { shutdown_services.call("SIGINT") }
  Signal.trap("TERM") { shutdown_services.call("SIGTERM") }

  puts "âœ… All services started successfully!"
  puts "ğŸ“Š Service URLs:"
  puts "   â€¢ Rails app:        http://localhost:3000"
  puts "   â€¢ AI Microservice:  http://localhost:8000" if start_ai_services
  puts "   â€¢ Ollama API:      http://localhost:11434" if start_ai_services
  puts ""
  puts "ğŸ¨ Asset builders are running in watch mode"
  puts "ğŸ’¡ Press Ctrl+C to stop all services gracefully"
  puts ""

  # Wait for any process to exit
  _, status = Process.wait2
  puts "\nğŸ”„ Process exited with status: #{status.exitstatus}"
  exit(status.exitstatus || 0)
  
rescue Interrupt
  puts "\nğŸ›‘ Interrupted by user"
  shutdown_services.call("USER_INTERRUPT")
rescue StandardError => e
  puts "\nâŒ Error: #{e.message}"
  puts e.backtrace.first(5)
  shutdown_services.call("ERROR")
ensure
  # Final cleanup
  if start_ai_services
    puts "ï¿½ Final cleanup..."
    
    # Clean up microservice PID file
    if File.exist?("tmp/ai_microservice.pid")
      File.delete("tmp/ai_microservice.pid") rescue nil
    end
  end
end
