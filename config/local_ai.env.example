# Local AI Services Configuration
# Set these environment variables to configure local AI services

# Local AI Microservice (Python)
# The microservice provides: YOLOv8, RetinaFace, InsightFace, PaddleOCR, Whisper
LOCAL_AI_SERVICE_URL=http://localhost:8000
USE_LOCAL_AI_MICROSERVICE=true

# Ollama (Local LLM)
# Provides local LLM inference for comment generation
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b

# Whisper Configuration (Fallback)
# Used if microservice is unavailable
WHISPER_BIN=whisper
WHISPER_MODEL=base

# Face Recognition Settings
FACE_RECOGNITION_THRESHOLD=0.6
FACE_EMBEDDING_SIZE=512

# Video Processing Settings
VIDEO_SAMPLE_RATE=2  # Sample every 2 seconds
MAX_VIDEO_SIZE_MB=100

# Performance Settings
AI_REQUEST_TIMEOUT=120
AI_CONCURRENT_REQUESTS=3
AI_VISUAL_TIMEOUT_SECONDS=210
AI_FACE_TIMEOUT_SECONDS=180
AI_OCR_TIMEOUT_SECONDS=150
AI_VIDEO_TIMEOUT_SECONDS=180

# AI Queue Concurrency (Sidekiq capsules)
SIDEKIQ_AI_VISUAL_CONCURRENCY=2
SIDEKIQ_AI_FACE_CONCURRENCY=2
SIDEKIQ_AI_FACE_REFRESH_CONCURRENCY=1
SIDEKIQ_AI_OCR_CONCURRENCY=1
SIDEKIQ_AI_VIDEO_CONCURRENCY=1
SIDEKIQ_AI_METADATA_CONCURRENCY=1

# Resource Guard (defer non-critical OCR/video work under pressure)
AI_MAX_LOAD_PER_CORE=1.20
AI_MIN_AVAILABLE_MEMORY_MB=700
AI_MAX_QUEUE_DEPTH=220
AI_RESOURCE_RETRY_SECONDS=20

# Health Cache
AI_HEALTH_CACHE_TTL_SECONDS=900
AI_HEALTH_STALE_AFTER_SECONDS=240

# Cost Optimization
ENABLE_LOCAL_FALLBACK=true
PREFER_LOCAL_OVER_CLOUD=true
